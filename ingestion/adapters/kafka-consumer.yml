input:
  label: kafka_logs
  kafka:
    addresses: [ ${KAFKA_BROKERS:localhost:9092} ]
    topics: ${KAFKA_TOPIC:logs.raw}
    consumer_group: ${KAFKA_CONSUMER_GROUP:benthos-adapter}
    client_id: ${KAFKA_CLIENT_ID:benthos-adapter}
    start_offset: earliest
    commit_period: 1s

pipeline:
  processors:
    - label: optional_rate_limit
      switch:
        - check: env("RATE_LIMIT_ENABLED").or("false") == "true"
          processors:
            - throttle:
                count: ${RATE_LIMIT_COUNT:1000}
                period: ${RATE_LIMIT_PERIOD:1s}
                drop: true
    - label: normalize_kafka
      mapping: |
        let org_id = env("DEFAULT_ORG_ID").or("")
        let ts = now()
        root.log_content = content().string()
        root.client_source_org_id = $org_id
        root.client_timestamp = $ts.format_timestamp("2006-01-02T15:04:05.000000000Z07:00")
        meta.source = "kafka"

output:
  http_client:
    url: ${INGESTION_ENDPOINT:http://ingestion:8091/v1/logs}
    verb: POST
    headers:
      Content-Type: application/json
      X-Source-Adapter: kafka
      X-Api-Key: ${INGESTION_API_KEY:}
    timeout: 5s
    retries: 10
    retry_period: 2s
    max_retry_backoff: 1m
    batching:
      count: ${HTTP_BATCH_COUNT:50}
      period: ${HTTP_BATCH_PERIOD:1s}